{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 1\n",
    "#### Kevin Saavedra\n",
    "\n",
    "This assignment was completed using the Python with the Pandas data analysis libary. It was run using Jupyter notebooks, which is being encouraged at Metro for data sharing and reproducibility purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/Users/kevin/Desktop/USP_587_data/OHAS_v2/household.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cdc1eb372f38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m df = pd.read_csv(os.path.join(\n\u001b[0;32m      7\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__file__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     wd + 'household.csv'), usecols=['resty', 'income', 'hhveh', 'htrips'])\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Count number of rows/columns in dataset:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\python3.6\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\python3.6\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\python3.6\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\python3.6\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\python3.6\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'/Users/kevin/Desktop/USP_587_data/OHAS_v2/household.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "wd = '/Users/kevin/Desktop/USP_587_data/OHAS_v2/'\n",
    "\n",
    "df = pd.read_csv(os.path.join(\n",
    "    os.path.dirname(\"__file__\"), \n",
    "    wd + 'household.csv'), usecols=['resty', 'income', 'hhveh', 'htrips'])\n",
    "\n",
    "# Count number of rows/columns in dataset:\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6444.000000\n",
       "mean        1.395872\n",
       "std         0.825739\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         7.000000\n",
       "Name: resty, dtype: float64"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exclude responses of 9 'REFUSED'\n",
    "df_resty = df.loc[df['resty'] != 9]\n",
    "df_resty['resty'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6019.000000\n",
       "mean        5.056156\n",
       "std         1.911337\n",
       "min         1.000000\n",
       "25%         4.000000\n",
       "50%         5.000000\n",
       "75%         7.000000\n",
       "max         8.000000\n",
       "Name: income, dtype: float64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exclude responses of 99 'REFUSED'\n",
    "df_inc = df.loc[df['income'] != 99]\n",
    "df_inc['income'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6449.000000\n",
       "mean        1.948209\n",
       "std         1.124169\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         2.000000\n",
       "max         8.000000\n",
       "Name: hhveh, dtype: float64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_veh = df.loc[df['hhveh'] != 99]\n",
    "df_veh['hhveh'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6014.000000\n",
       "mean        9.840871\n",
       "std         7.763646\n",
       "min         0.000000\n",
       "25%         4.000000\n",
       "50%         8.000000\n",
       "75%        14.000000\n",
       "max        65.000000\n",
       "Name: htrips, dtype: float64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['htrips'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Calculate average number of trips by vehicle:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hhveh\n",
      "0     7.925072\n",
      "1     6.988945\n",
      "2    11.066562\n",
      "3    11.666027\n",
      "4    12.160350\n",
      "5    12.377358\n",
      "6    10.906977\n",
      "7    13.416667\n",
      "8     8.916667\n",
      "Name: htrips, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_v1 = df.groupby(['hhveh'])['htrips'].mean()\n",
    "print(df_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Calculate average number of trips by income:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "income\n",
      "1      6.359873\n",
      "2      6.837113\n",
      "3      6.828810\n",
      "4      8.079408\n",
      "5      9.677517\n",
      "6     11.241623\n",
      "7     12.244817\n",
      "8     12.622642\n",
      "99     9.500000\n",
      "Name: htrips, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_vi = df.groupby(['income'])['htrips'].mean()\n",
    "print(df_vi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Based on your calculation, how do you describe the relationship between number of vehicles and number of trips?*\n",
    "\n",
    "Having two or more vehicles generally sees an increase in number of trips compared to zero or single-car households. The largest jump is from 1 to 2 cars per household, a 57% increase in trips. However, there is little difference between having 2-7 cars per household in terms of trips. The highest number of cars owned per household (8) actually sees fewer trips than the next highest categories.\n",
    "\n",
    "*Income?*\n",
    "\n",
    "Lowest income levels have similar numbers of trips, but generally speaking, the number of trips increase with income. Again, the highest income group drops off in terms of trips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create a new variable INC_CAT that collapses the 8 income categories in the raw INCOME column into 3 categories (e.g. $0 - $24,999, $25,000 - $49,999, $50,000 and above). Count number of households within each INC_CAT and then calculate average number of trips by INC_CAT.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total numbers of households per INC_CAT:\n",
      "inc_cat\n",
      "1.0     799\n",
      "2.0    1222\n",
      "3.0    4428\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Average number of trips by INC_CAT:\n",
      "inc_cat\n",
      "1.0     6.649562\n",
      "2.0     7.589198\n",
      "3.0    11.000678\n",
      "Name: htrips, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def income_categorizer(df_inc):\n",
    "    for index, row in df_inc.iterrows():\n",
    "        if row.income <= 2:\n",
    "            df_inc.set_value(index, 'inc_cat', 1)\n",
    "        elif row.income >= 3 and row.income <= 4:\n",
    "            df_inc.set_value(index, 'inc_cat', 2)\n",
    "        elif row.income >= 5:\n",
    "            df_inc.set_value(index, 'inc_cat', 3)\n",
    "    return df_inc\n",
    "        \n",
    "df_new_inc_cat = income_categorizer(df)\n",
    "print(\"Total numbers of households per INC_CAT:\")\n",
    "print(df_new_inc_cat.groupby(['inc_cat']).size())\n",
    "print(\"\\n\")\n",
    "print(\"Average number of trips by INC_CAT:\")\n",
    "print(df_new_inc_cat.groupby(['inc_cat'])['htrips'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create a new variable INCVAL that is equal to the mid-point of the range for categories 1 through 7 and $250,000 for category 8 (Set missing values for category 99). Run frequencies and summary to compute the mean and standard deviation for this new variable. Calculate the correlation between INCVAL and number of trips (HTRIPS).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             hhveh        resty       income       htrips      inc_cat  \\\n",
      "count  6449.000000  6449.000000  6449.000000  6449.000000  6449.000000   \n",
      "mean      1.948209     1.401768    11.320050     9.815165     2.562723   \n",
      "std       1.124169     0.852127    23.509842     7.819117     0.702804   \n",
      "min       0.000000     1.000000     1.000000     0.000000     1.000000   \n",
      "25%       1.000000     1.000000     4.000000     4.000000     2.000000   \n",
      "50%       2.000000     1.000000     5.000000     8.000000     3.000000   \n",
      "75%       2.000000     1.000000     7.000000    14.000000     3.000000   \n",
      "max       8.000000     9.000000    99.000000    81.000000     3.000000   \n",
      "\n",
      "              incval  \n",
      "count    6019.000000  \n",
      "mean    82889.558980  \n",
      "std     62390.205001  \n",
      "min      7499.500000  \n",
      "25%     42499.500000  \n",
      "50%     62499.500000  \n",
      "75%    124999.500000  \n",
      "max    250000.000000  \n"
     ]
    }
   ],
   "source": [
    "def set_incval(df_incval):\n",
    "    for index, row in df_incval.iterrows():\n",
    "        if row.income == 1:\n",
    "            df_incval.set_value(index, 'incval', ((14999-0)/2 + 0))\n",
    "        elif row.income == 2:\n",
    "            df_incval.set_value(index, 'incval', ((15000-24999)/2 + 24999))\n",
    "        elif row.income == 3:\n",
    "            df_incval.set_value(index, 'incval', ((34999-25000)/2 + 25000))\n",
    "        elif row.income == 4:\n",
    "            df_incval.set_value(index, 'incval', ((49999-35000)/2 + 35000))\n",
    "        elif row.income == 5:\n",
    "            df_incval.set_value(index, 'incval', ((74999-50000)/2 + 50000))\n",
    "        elif row.income == 6:\n",
    "            df_incval.set_value(index, 'incval', ((99999-75000)/2 + 75000)) \n",
    "        elif row.income == 7:\n",
    "            df_incval.set_value(index, 'incval', ((149999-100000)/2 + 100000))\n",
    "        elif row.income == 8:\n",
    "            df_incval.set_value(index, 'incval', 250000)\n",
    "        elif row.income == 99:\n",
    "            df_incval.set_value(index, 'incval', None)          \n",
    "    return df_incval\n",
    "\n",
    "df_incval_new = set_incval(df_new_inc_cat)\n",
    "print(df_incval_new.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain why the mean and standard deviation from the original income category (INCOME) variable would not be useful.*\n",
    "\n",
    "Original INCOME variables are not useful since they are coded values and do accurately convey the actual dollar amounts needed for useful analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Calculate the correlation between INCVAL and number of trips*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between incval and htrips:\n",
      "0.227872645556\n"
     ]
    }
   ],
   "source": [
    "print('Correlation between incval and htrips:')\n",
    "print(df_incval_new['incval'].corr(df_incval_new['htrips']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Recode HHVEH into a new variable HHVEH_CAT to reduce the size of the table (this will make interpretation easier). Use judgment about which groups to combine (review your frequency analysis in Question a) in making these judgments). You can accomplish the regrouping by using the RECODE command in SPSS (or cut function in R and if function in Excel). When grouping variables, you should create a new variable and modify the variable name value labels appropriately. Calculate average number of trips by HHVEH_CAT. What is the advantage of this calculation comparing with the average number of trips by number of vehicles in question b)?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hhveh_cat\n",
      "0.0     7.997006\n",
      "1.0     7.002183\n",
      "2.0    11.125842\n",
      "3.0    11.718071\n",
      "Name: htrips, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def vehicle_categorizer(df_veh):\n",
    "    for index, row in df_inc.iterrows():\n",
    "        if row.hhveh == 0:\n",
    "            df_veh.set_value(index, 'hhveh_cat', 0)\n",
    "        elif row.hhveh == 1:\n",
    "            df_veh.set_value(index, 'hhveh_cat', 1)\n",
    "        elif row.hhveh == 2:\n",
    "            df_veh.set_value(index, 'hhveh_cat', 2)\n",
    "        elif row.hhveh >= 3:\n",
    "            df_veh.set_value(index, 'hhveh_cat', 3)\n",
    "    return df_veh\n",
    "\n",
    "\n",
    "df_veh_cat_new = vehicle_categorizer(df)\n",
    "print(df_veh_cat_new.groupby(['hhveh_cat'])['htrips'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What is the advantage of this calculation comparing with the average number of trips by number of vehicles in question b)?*\n",
    "\n",
    "Regrouping the hhveh number allows us to better match average vehicle ownership rates per household in the U.S. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between income and htrips:\n",
      "0.266964320558\n",
      "Correlation between incval and htrips:\n",
      "0.227872645556\n",
      "Correlation between inc_cat and htrips:\n",
      "0.234081447426\n",
      "Correlation between hhveh and htrips:\n",
      "0.202439549024\n",
      "Correlation between hhveh_cat and htrips:\n",
      "0.228604295745\n"
     ]
    }
   ],
   "source": [
    "print('Correlation between income and htrips:')\n",
    "print(df_veh_cat_new['income'].corr(df_veh_cat_new['htrips']))\n",
    "print('Correlation between incval and htrips:')\n",
    "print(df_veh_cat_new['incval'].corr(df_veh_cat_new['htrips']))\n",
    "print('Correlation between inc_cat and htrips:')\n",
    "print(df_veh_cat_new['inc_cat'].corr(df_veh_cat_new['htrips']))\n",
    "print('Correlation between hhveh and htrips:')\n",
    "print(df_veh_cat_new['hhveh'].corr(df_veh_cat_new['htrips']))\n",
    "print('Correlation between hhveh_cat and htrips:')\n",
    "print(df_veh_cat_new['hhveh_cat'].corr(df_veh_cat_new['htrips']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between income and resty:\n",
      "-0.393130280469\n",
      "Correlation between incval and resty:\n",
      "-0.288473772987\n",
      "Correlation between inc_cat and resty:\n",
      "-0.385595887363\n",
      "Correlation between hhveh and resty:\n",
      "-0.374949618769\n",
      "Correlation between hhveh_cat and resty:\n",
      "-0.430969976531\n"
     ]
    }
   ],
   "source": [
    "print('Correlation between income and resty:')\n",
    "print(df_veh_cat_new['income'].corr(df_veh_cat_new['resty']))\n",
    "print('Correlation between incval and resty:')\n",
    "print(df_veh_cat_new['incval'].corr(df_veh_cat_new['resty']))\n",
    "print('Correlation between inc_cat and resty:')\n",
    "print(df_veh_cat_new['inc_cat'].corr(df_veh_cat_new['resty']))\n",
    "print('Correlation between hhveh and resty:')\n",
    "print(df_veh_cat_new['hhveh'].corr(df_veh_cat_new['resty']))\n",
    "print('Correlation between hhveh_cat and resty:')\n",
    "print(df_veh_cat_new['hhveh_cat'].corr(df_veh_cat_new['resty']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain what the weight column (hhwgt and exphhwgt) is (or does)?*\n",
    "\n",
    "Weights households to give more emphasis to certain responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create a new variable by multiplying the number of trips with the household weighting factor (exphhwgt), for example, for the first household in the household table in OHAS data set, 3 vehicles &ast; weighting factor of 217.05 = 651.15 weighted vehicles*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hhveh         3.000000\n",
      "resty         1.000000\n",
      "income        5.000000\n",
      "htrips        6.000000\n",
      "hhwgt         1.591203\n",
      "exphhwgt    217.054444\n",
      "hhvehwgt    651.163331\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(\n",
    "    os.path.dirname(\"__file__\"), \n",
    "    wd + 'household.csv'), usecols=['resty', 'income', 'hhveh', \n",
    "                                    'hhwgt', 'htrips', 'exphhwgt'])\n",
    "df['hhvehwgt'] = df['exphhwgt'] * df['hhveh']\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sum the new variable created in step 1 over all samples (households) and sum the entire weighting factor (exphhwgt) over all samples (households);*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hhvehwgt sum = 1487688.8128576986\n",
      "exphhwgt sum = 807567.0000014375\n"
     ]
    }
   ],
   "source": [
    "sum_hhvehwgt = df['hhvehwgt'].sum()\n",
    "sum_exphhwgt = df['exphhwgt'].sum()\n",
    "print(\"hhvehwgt sum =\", sum_hhvehwgt)\n",
    "print(\"exphhwgt sum =\", sum_exphhwgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Divide the sum of weighted variable by the sum of weighting factors and you get the weighted average (mean)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted average = 1.8421862369995932\n"
     ]
    }
   ],
   "source": [
    "print(\"Weighted average =\", sum_hhvehwgt / sum_exphhwgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9482090246549852\n"
     ]
    }
   ],
   "source": [
    "hhveh_avg = df['hhveh'].mean()\n",
    "print(hhveh_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Is there a difference between the average number of vehicles and the weighted average number of vehicles? If so, what does the difference tell you?*\n",
    "\n",
    "Yes, there is a very slight difference between the weighted average and the vehicular average, which means that the survey response may be recording slightly higher vehicle numbers than is accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Following the same steps above, compute the percent of households that use transit at least once a week (the RIBUS column) without and with the household weighting factor.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ribus unweighted = 1.3809380521963068 percent\n",
      "ribus weighted = 28.599366847117153 percent\n"
     ]
    }
   ],
   "source": [
    "def calc_ribus(df_ribus):\n",
    "    for index, row in df_ribus.iterrows():\n",
    "        if row.ribus == 1:\n",
    "            df_ribus.set_value(index, 'ribus_count', 1)\n",
    "    return df_ribus\n",
    "\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(os.path.join(\n",
    "    os.path.dirname(\"__file__\"), \n",
    "    wd + 'household.csv'), usecols=['resty', 'income', 'hhveh', \n",
    "                                    'ribus', 'htrips', 'hhwgt', 'exphhwgt'])\n",
    "# Apply ribus calculation function\n",
    "df = calc_ribus(df)\n",
    "\n",
    "df['ribuswgt'] = df['exphhwgt'] * df['ribus_count']\n",
    "hh_count = df.shape[0]\n",
    "ribus_pct = (df['ribus'].sum() / df['exphhwgt'].sum()) * 100\n",
    "ribuswgt_pct = (df['ribuswgt'].sum() / df['exphhwgt'].sum()) * 100\n",
    "print(\"ribus unweighted =\", ribus_pct, 'percent')\n",
    "print(\"ribus weighted =\", ribuswgt_pct, 'percent')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
